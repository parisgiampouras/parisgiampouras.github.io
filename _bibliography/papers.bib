---
---


 preview={brownian-motion.gif}

@ARTICLE{9735405,  
bibtex_show = {true}
abbr={IEEE TSP},
author={Giampouras, Paris V. and Rontogiannis, Athanasios A. and Kofidis, Eleftherios},  
journal={IEEE Transactions on Signal Processing},  
title={Block-Term Tensor Decomposition Model Selection and Computation: The Bayesian Way},   
year={2022},  
volume={70},  number={},  
pages={1704-1717},  
doi={10.1109/TSP.2022.3159029}
}

@ARTICLE{8552430,  
abbr={IEEE TSP},
bibtex_show={true},
author={Giampouras, Paris V. and Rontogiannis, Athanasios A. and Koutroumbas, Konstantinos D.}, 
journal={IEEE Transactions on Signal Processing}, 
title={Alternating Iteratively Reweighted Least Squares Minimization for Low-Rank Matrix Factorization},  
year={2019}, 
volume={67}, 
number={2},  
pages={490-503}, 
doi={10.1109/TSP.2018.2883921},
selected={true}
}

@article{7460933, 
abbr={IEEE TGRS},
bibtex_show={true},
title={Simultaneously Sparse and Low-Rank Abundance Matrix Estimation for Hyperspectral Image Unmixing},  
author={Giampouras, Paris V. and Themelis, Konstantinos E. and Rontogiannis, Athanasios A. 
and Koutroumbas, Konstantinos D.}, 
journal={IEEE Transactions on Geoscience and Remote Sensing},  

year={2016},  
volume={54},  
number={8},  
pages={4775-4789}, 
doi={10.1109/TGRS.2016.2551327},
}

@article{GIAMPOURAS2017199,
abbr={Elsevier SP},
bibtex_show={true},
title = {Online sparse and low-rank subspace learning from incomplete data: A Bayesian view},
journal = {Signal Processing},
volume = {137},
pages = {199-212},
year = {2017},
issn = {0165-1684},
doi = {https://doi.org/10.1016/j.sigpro.2017.02.003},
url = {https://www.sciencedirect.com/science/article/pii/S016516841730049X},
author = {Paris V. Giampouras and Athanasios A. Rontogiannis and Konstantinos E. Themelis and Konstantinos D. Koutroumbas},
keywords = {Subspace tracking, Online matrix completion, Online variational Bayes, Incomplete data, Sparse subspace learning, Low-rank},
abstract = {Extracting the underlying low-dimensional space where high-dimensional signals often reside has been at the center of numerous algorithms in the signal processing and machine learning literature during the past few decades. Moreover, working with incomplete large scale datasets has recently been commonplace for diverse reasons. This so called big data era we are currently living calls for devising online subspace learning algorithms that can suitably handle incomplete data. Their anticipated goal is to recursively estimate the unknown subspace by processing streaming data sequentially, thus reducing computational complexity. In this paper, an online variational Bayes subspace learning algorithm from partial observations is presented. To account for the unawareness of the true rank of the subspace, commonly met in practice, low-rankness is explicitly imposed on the sought subspace data matrix by exploiting sparse Bayesian learning principles. Sparsity, simultaneously to low-rankness, is favored on the subspace matrix by the sophisticated hierarchical Bayesian scheme that is adopted. The proposed algorithm is thus adept in dealing with applications whereby the underlying subspace may be also sparse. The new subspace tracking scheme outperforms its state-of-the-art counterparts in terms of estimation accuracy, in a variety of experiments conducted on both simulated and real data.}
}

@ARTICLE{9149633,  
abbr={IEEE SP letters},
bibtex_show={true},
author={Rontogiannis, Athanasios A. and Giampouras, Paris V. and Koutroumbas, Konstantinos D.},
journal={IEEE Signal Processing Letters},   title={Online Reweighted Least Squares Robust PCA},  
year={2020},  volume={27},  number={},  pages={1340-1344}, 
doi={10.1109/LSP.2020.3011896}}


@INPROCEEDINGS{9415104, 
abbr={ICASSP},
bibtex_show={true},
author={Rontogiannis, Athanasios A. and Giampouras, Paris V and Kofidis, Eleftherios}, 
booktitle={2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
title={Rank-Revealing Block-Term Decomposition for Tensor Completion},  
year={2021},  volume={},  
number={}, 
pages={2915-2919},  
doi={10.1109/ICASSP39728.2021.9415104}
}

@ARTICLE{9321500, 
abbr={IEEE JSTSP},
bibtex_show={true},
author={Rontogiannis, Athanasios A. and Kofidis, Eleftherios and Giampouras, Paris V.}, 
journal={IEEE Journal of Selected Topics in Signal Processing},  
title={Block-Term Tensor Decomposition: Model Selection and Computation},   
year={2021},  volume={15},  number={3},
pages={464-475},  
doi={10.1109/JSTSP.2021.3051488}
}




@inproceedings{
giampouras2022implicit,
abbr = {ICLR},
bibtex_show={true},
title={Implicit Bias of Projected Subgradient Method Gives Provable Robust Recovery of Subspaces of Unknown Codimension},
author={Paris Giampouras and Benjamin David Haeffele and Rene Vidal},
booktitle={International Conference on Learning Representations},
year={2022},
url={https://openreview.net/forum?id=vA7doMdgi75}
selected={true}
}

@InProceedings{pmlr-v162-thaker22a,
  abbr={ICML},
  bibtex_show={true},
  title = 	 {Reverse Engineering $\ell_p$ attacks: A block-sparse optimization approach with recovery guarantees},
  author =       {Thaker, Darshan and Giampouras, Paris and Vidal, Rene},
  booktitle = 	 {Proceedings of the 39th International Conference on Machine Learning},
  pages = 	 {21253--21271},
  year = 	 {2022},
  editor = 	 {Chaudhuri, Kamalika and Jegelka, Stefanie and Song, Le and Szepesvari, Csaba and Niu, Gang and Sabato, Sivan},
  volume = 	 {162},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {17--23 Jul},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v162/thaker22a/thaker22a.pdf},
  url = 	 {https://proceedings.mlr.press/v162/thaker22a.html},
  abstract = 	 {Deep neural network-based classifiers have been shown to be vulnerable to imperceptible perturbations to their input, such as $\ell_p$-bounded norm adversarial attacks. This has motivated the development of many defense methods, which are then broken by new attacks, and so on. This paper focuses on a different but related problem of reverse engineering adversarial attacks. Specifically, given an attacked signal, we study conditions under which one can determine the type of attack ($\ell_1$, $\ell_2$ or $\ell_\infty$) and recover the clean signal. We pose this problem as a block-sparse recovery problem, where both the signal and the attack are assumed to lie in a union of subspaces that includes one subspace per class and one subspace per attack type. We derive geometric conditions on the subspaces under which any attacked signal can be decomposed as the sum of a clean signal plus an attack. In addition, by determining the subspaces that contain the signal and the attack, we can also classify the signal and determine the attack type. Experiments on digit and face classification demonstrate the effectiveness of the proposed approach.},
  selected={true}
}


